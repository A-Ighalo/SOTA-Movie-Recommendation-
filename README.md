# SOTA-Movie-Recommendation-

# Fair and Equitable AI in Recommendation Systems

**Author:** Abraham Ho  
**Last Updated:** August 2025  
**Status:** Active Development  


---

## ðŸ“Œ Overview

This project develops a **fairness-aware recommendation system** that aims to provide relevant and personalized results **without reinforcing existing biases**.  

By combining:
- **Exploratory Data Analysis (EDA)**
- **Bias detection & mitigation techniques**
- **Fairness metrics**
- **MLflow experiment tracking**

â€¦we ensure that both **accuracy** and **equity** are integral to the system.

---

## ðŸŽ¯ Objectives

1. **Detect and quantify bias** in recommendation outputs.  
2. **Mitigate disparate impacts** while preserving recommendation quality.  
3. Track experiments with **MLflow** for transparency and reproducibility.  
4. Provide a **reproducible pipeline** for fairness-aware recommender systems.

---

## ðŸ“Š Key Fairness Concepts

- **Disparate Impact** â€“ Avoid situations where one group systematically receives less favorable recommendations.
- **Exposure Parity** â€“ Ensure balanced visibility for items from diverse providers.
- **Calibration** â€“ Maintain consistency between predicted relevance and actual outcomes across groups.

---

## ðŸ—‚ Project Structure

```plaintext
â”œâ”€â”€ data/                # Raw and processed datasets
â”œâ”€â”€ notebooks/           # Jupyter notebooks for EDA and modeling
â”œâ”€â”€ src/                 # Source code for recommendation algorithms
â”œâ”€â”€ mlruns/              # MLflow experiment logs
â”œâ”€â”€ README.md            # Project documentation
â””â”€â”€ requirements.txt     # Dependencies


```
<img width="1271" height="426" alt="image" src="https://github.com/user-attachments/assets/320600b4-3672-4445-952e-8a8f99e0122e" />
